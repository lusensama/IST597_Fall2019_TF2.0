{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "author:-aam35\n",
    "\"\"\"\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL']='2'\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "# from sklearn.metrics import confusion_matrix\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def load_mnist(path, kind='train', val_size = 0.0):\n",
    "    import os\n",
    "    import gzip\n",
    "    import numpy as np\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "    \"\"\"Load MNIST data from `path`\"\"\"\n",
    "    labels_path = os.path.join(path,\n",
    "                               '%s-labels-idx1-ubyte.gz'\n",
    "                               % kind)\n",
    "    images_path = os.path.join(path,\n",
    "                               '%s-images-idx3-ubyte.gz'\n",
    "                               % kind)\n",
    "\n",
    "    with gzip.open(labels_path, 'rb') as lbpath:\n",
    "        labels = np.frombuffer(lbpath.read(), dtype=np.uint8,\n",
    "                               offset=8)\n",
    "\n",
    "    with gzip.open(images_path, 'rb') as imgpath:\n",
    "        images = np.frombuffer(imgpath.read(), dtype=np.uint8,\n",
    "                               offset=16).reshape(len(labels), 784)\n",
    "    # if kind=='train':\n",
    "    #     return train_test_split(images, labels, test_size=val_size, random_state=13)\n",
    "    # else:\n",
    "    img = images.reshape([-1, 28, 28, 1])\n",
    "    return img, labels\n",
    "\n",
    "\n",
    "# Define paramaters for the model\n",
    "learning_rate = 0.001\n",
    "batch_size = 32\n",
    "n_epochs = 10\n",
    "n_train = None\n",
    "n_test = None\n",
    "n_classes = 10\n",
    "n_channel = 1\n",
    "pixel_depth = 255\n",
    "image_size = 28\n",
    "seed = None\n",
    "\n",
    "# Step 1: Read in data\n",
    "fmnist_folder = './data/'\n",
    "train_data, train_label= load_mnist('./data/')\n",
    "test_data, test_label = load_mnist('./data/', kind='t10k')\n",
    "#Create train,validation,test split\n",
    "#train, val, test = utils.read_fmnist(fmnist_folder, flatten=True)\n",
    "\n",
    "# train_data = tfds.load('fashion_mnist', tfds.Split.TRAIN)\n",
    "# eval_data = tfds.load('fashion_mnist', tfds.Split.VALIDATION)\n",
    "# test_data = tfds.load('fashion_mnist', tfds.Split.TEST)\n",
    "# Step 2: Create datasets and iterator\n",
    "# create training Dataset and batch it\n",
    "\n",
    "# SHUFFLE_BUFFER_SIZE = 100\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_data, train_label)).batch(batch_size)\n",
    "# val_dataset = tf.data.Dataset.from_tensor_slices((val_data, val_label))\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((test_data, test_label)).batch(batch_size)\n",
    "\n",
    "# create testing Dataset and batch it\n",
    "\n",
    "\n",
    "# train_dataset = train_dataset.batch_and_drop_remainder(BATCH_SIZE)\n",
    "# # val_dataset = val_dataset.batch(BATCH_SIZE)\n",
    "# test_dataset = test_dataset.batch_and_drop_remainder(BATCH_SIZE)\n",
    "\n",
    "# create one iterator and initialize it with different datasets\n",
    "\n",
    "# train_iterator = train_dataset[0:63]\n",
    "# train_img, train_label = train_iterator.get_next()\n",
    "#\n",
    "# train_init = iterator.make_initializer(train_data)\t# initializer for train_data\n",
    "# test_init = iterator.make_initializer(test_data)\t# initializer for train_data\n",
    "\n",
    "# Step 3: create weights and bias\n",
    "# w is initialized to random variables with mean of 0, stddev of 0.01\n",
    "# b is initialized to 0\n",
    "# shape of w depends on the dimension of X and Y so that Y = tf.matmul(X, w)\n",
    "# shape of b depends on Y\n",
    "# weight_initializer = tf.random_normal(mean=0.0, stddev=0.01)\n",
    "# step 2: create the weight variable with proper initialization\n",
    "# w = tf.get_variable(name=\"Weight\", dtype=tf.float32, shape=(train_data.shape[1],train_data.shape[0]), initializer=weight_initializer)\n",
    "\n",
    "# initialize biases as zero\n",
    "# step 1: create the initializer for biases\n",
    "# b =tf.constant(0., shape=train_label.shape, dtype=tf.float32)\n",
    "#############################\n",
    "########## TO DO ############\n",
    "#############################\n",
    "\n",
    "conv1_weights = tf.Variable(\n",
    "    tf.random.normal([5, 5, n_channel, 32],  # 5x5 filter, depth 32.\n",
    "                        stddev=0.1,\n",
    "                        seed=seed, dtype=tf.float32))\n",
    "conv1_biases = tf.Variable(tf.zeros([32], dtype=tf.float32))\n",
    "conv2_weights = tf.Variable(tf.random.normal(\n",
    "    [5, 5, 32, 64], stddev=0.1,\n",
    "    seed=seed, dtype=tf.float32))\n",
    "conv2_biases = tf.Variable(tf.constant(0.1, shape=[64], dtype=tf.float32))\n",
    "fc1_weights = tf.Variable(  # fully connected, depth 512.\n",
    "    tf.random.normal([image_size // 4 * image_size // 4 * 64, 512],\n",
    "                        stddev=0.1,\n",
    "                        seed=seed,\n",
    "                        dtype=tf.float32))\n",
    "fc1_biases = tf.Variable(tf.constant(0.1, shape=[512], dtype=tf.float32))\n",
    "fc2_weights = tf.Variable(tf.random.normal([512, n_classes],\n",
    "                                              stddev=0.1,\n",
    "                                              seed=seed,\n",
    "                                              dtype=tf.float32))\n",
    "fc2_biases = tf.Variable(tf.constant(\n",
    "    0.1, shape=[n_classes], dtype=tf.float32))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Step 4: build model\n",
    "# the model that returns the logits.\n",
    "# this logits will be later passed through softmax layer\n",
    "def model(data, train=False):\n",
    "    \"\"\"The Model definition.\"\"\"\n",
    "    # 2D convolution, with 'SAME' padding (i.e. the output feature map has\n",
    "    # the same size as the input). Note that {strides} is a 4D array whose\n",
    "    # shape matches the data layout: [image index, y, x, depth].\n",
    "    data = tf.cast(data, tf.float32)\n",
    "    conv = tf.nn.conv2d(data,\n",
    "                        conv1_weights,\n",
    "                        strides=[1, 1, 1, 1],\n",
    "                        padding='SAME')\n",
    "    # Bias and rectified linear non-linearity.\n",
    "    relu = tf.nn.relu(tf.nn.bias_add(conv, conv1_biases))\n",
    "    # Max pooling. The kernel size spec {ksize} also follows the layout of\n",
    "    # the data. Here we have a pooling window of 2, and a stride of 2.\n",
    "    pool = tf.nn.max_pool(relu,\n",
    "                          ksize=[1, 2, 2, 1],\n",
    "                          strides=[1, 2, 2, 1],\n",
    "                          padding='SAME')\n",
    "    conv = tf.nn.conv2d(pool,\n",
    "                        conv2_weights,\n",
    "                        strides=[1, 1, 1, 1],\n",
    "                        padding='SAME')\n",
    "    relu = tf.nn.relu(tf.nn.bias_add(conv, conv2_biases))\n",
    "    pool = tf.nn.max_pool(relu,\n",
    "                          ksize=[1, 2, 2, 1],\n",
    "                          strides=[1, 2, 2, 1],\n",
    "                          padding='SAME')\n",
    "    # Reshape the feature map cuboid into a 2D matrix to feed it to the\n",
    "    # fully connected layers.\n",
    "    pool_shape = pool.get_shape().as_list()\n",
    "    reshape = tf.reshape(\n",
    "        pool,\n",
    "        [pool_shape[0], pool_shape[1] * pool_shape[2] * pool_shape[3]])\n",
    "    # Fully connected layer. Note that the '+' operation automatically\n",
    "    # broadcasts the biases.\n",
    "    hidden = tf.nn.relu(tf.matmul(reshape, fc1_weights) + fc1_biases)\n",
    "    # Add a 50% dropout during training only. Dropout also scales\n",
    "    # activations such that no rescaling is needed at evaluation time.\n",
    "    if train:\n",
    "        hidden = tf.nn.dropout(hidden, 0.5, seed=seed)\n",
    "    return tf.matmul(hidden, fc2_weights) + fc2_biases\n",
    "\n",
    "\n",
    "#############################\n",
    "########## TO DO ############\n",
    "#############################\n",
    "\n",
    "\n",
    "# Step 5: define loss function\n",
    "# use cross entropy of softmax of logits as the loss function\n",
    "\n",
    "def loss_func(logit, y):\n",
    "    return tf.compat.v2.nn.softmax_cross_entropy_with_logits(labels=tf.reshape(y,(batch_size, 1)), logits=logit)\n",
    "\n",
    "\n",
    "def train(inputs, targets):\n",
    "    loss_value = loss_func(inputs, targets)\n",
    "    return loss_value\n",
    "\n",
    "iter = train_dataset.__iter__()\n",
    "train_img, train_lbl = iter.next()\n",
    "optimizer = tf.compat.v1.train.AdamOptimizer(learning_rate)\n",
    "\n",
    "for i in range(n_epochs):\n",
    "    for j in range(train_data.shape[0]//batch_size):\n",
    "        with tf.GradientTape() as tape:\n",
    "            logits = model(train_img, train=True)\n",
    "            loss_value = train(logits, train_lbl)\n",
    "\n",
    "        dc1w, dc1b ,dc2w, dc2b, df1w, df1b, df2w, df2b= tape.gradient(loss_value, [conv1_weights, conv1_biases,\n",
    "                                                                                    conv2_weights, conv2_biases,\n",
    "                                                                                    fc1_weights, fc1_biases,\n",
    "                                                                                    fc2_weights, fc2_biases,])\n",
    "        optimizer.apply_gradients(zip([dc1w, dc1b ,dc2w, dc2b, df1w, df1b, df2w, df2b],\n",
    "                                      [conv1_weights, conv1_biases,\n",
    "                                       conv2_weights, conv2_biases,\n",
    "                                       fc1_weights, fc1_biases,\n",
    "                                       fc2_weights, fc2_biases, ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "itert = test_dataset.__iter__()\n",
    "test_img, test_lbl = iter.next()\n",
    "logits = model(test_img, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=3398109, shape=(32, 10), dtype=float32, numpy=\n",
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]], dtype=float32)>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = tf.nn.softmax(logits)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=3398108, shape=(32,), dtype=bool, numpy=\n",
       "array([False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False])>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_preds = tf.equal(tf.argmax(preds, axis=-1), tf.argmax(test_lbl, axis=-1))\n",
    "correct_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=3398102, shape=(32, 10), dtype=float32, numpy=\n",
       "array([[7.07752336e+17, 7.07713578e+17, 7.07625480e+17, 7.07765805e+17,\n",
       "        7.07771715e+17, 7.07703683e+17, 7.07693238e+17, 7.07755085e+17,\n",
       "        7.07735981e+17, 7.07814390e+17],\n",
       "       [1.38965969e+17, 1.38958358e+17, 1.38941067e+17, 1.38968632e+17,\n",
       "        1.38969783e+17, 1.38956400e+17, 1.38954355e+17, 1.38966519e+17,\n",
       "        1.38962748e+17, 1.38978149e+17],\n",
       "       [1.97826881e+17, 1.97816023e+17, 1.97791422e+17, 1.97830626e+17,\n",
       "        1.97832310e+17, 1.97813274e+17, 1.97810354e+17, 1.97827637e+17,\n",
       "        1.97822311e+17, 1.97844233e+17],\n",
       "       [4.07238629e+17, 4.07216329e+17, 4.07165648e+17, 4.07246359e+17,\n",
       "        4.07249761e+17, 4.07210625e+17, 4.07204578e+17, 4.07240209e+17,\n",
       "        4.07229180e+17, 4.07274294e+17],\n",
       "       [4.07498491e+17, 4.07476192e+17, 4.07425442e+17, 4.07506291e+17,\n",
       "        4.07509624e+17, 4.07470454e+17, 4.07464441e+17, 4.07500037e+17,\n",
       "        4.07489008e+17, 4.07534225e+17],\n",
       "       [4.67844912e+17, 4.67819314e+17, 4.67761040e+17, 4.67853811e+17,\n",
       "        4.67857660e+17, 4.67812786e+17, 4.67805811e+17, 4.67846699e+17,\n",
       "        4.67834089e+17, 4.67885903e+17],\n",
       "       [5.04761943e+17, 5.04734317e+17, 5.04671508e+17, 5.04771563e+17,\n",
       "        5.04775755e+17, 5.04727239e+17, 5.04719749e+17, 5.04763901e+17,\n",
       "        5.04750260e+17, 5.04806267e+17],\n",
       "       [9.45301274e+17, 9.45249528e+17, 9.45131811e+17, 9.45319416e+17,\n",
       "        9.45327112e+17, 9.45236265e+17, 9.45222246e+17, 9.45304985e+17,\n",
       "        9.45279421e+17, 9.45384149e+17],\n",
       "       [7.70018230e+17, 7.69976036e+17, 7.69880241e+17, 7.70032935e+17,\n",
       "        7.70039258e+17, 7.69965316e+17, 7.69953908e+17, 7.70021184e+17,\n",
       "        7.70000362e+17, 7.70085712e+17],\n",
       "       [4.17880149e+17, 4.17857231e+17, 4.17805279e+17, 4.17888120e+17,\n",
       "        4.17891591e+17, 4.17851390e+17, 4.17845205e+17, 4.17881764e+17,\n",
       "        4.17870459e+17, 4.17916776e+17],\n",
       "       [6.68172804e+17, 6.68136314e+17, 6.68053026e+17, 6.68185586e+17,\n",
       "        6.68191152e+17, 6.68126899e+17, 6.68117004e+17, 6.68175415e+17,\n",
       "        6.68157411e+17, 6.68231422e+17],\n",
       "       [3.11856064e+17, 3.11838987e+17, 3.11800195e+17, 3.11862042e+17,\n",
       "        3.11864585e+17, 3.11834623e+17, 3.11830019e+17, 3.11857266e+17,\n",
       "        3.11848848e+17, 3.11883414e+17],\n",
       "       [9.00182402e+17, 9.00133130e+17, 9.00021048e+17, 9.00199582e+17,\n",
       "        9.00207072e+17, 9.00120554e+17, 9.00107154e+17, 9.00185975e+17,\n",
       "        9.00161511e+17, 9.00261360e+17],\n",
       "       [6.52413091e+17, 6.52377357e+17, 6.52296131e+17, 6.52425530e+17,\n",
       "        6.52430890e+17, 6.52368218e+17, 6.52358528e+17, 6.52415565e+17,\n",
       "        6.52397973e+17, 6.52470266e+17],\n",
       "       [3.69282147e+17, 3.69261909e+17, 3.69215970e+17, 3.69289156e+17,\n",
       "        3.69292215e+17, 3.69256755e+17, 3.69251258e+17, 3.69283556e+17,\n",
       "        3.69273592e+17, 3.69314514e+17],\n",
       "       [6.67573982e+17, 6.67537424e+17, 6.67454273e+17, 6.67586764e+17,\n",
       "        6.67592193e+17, 6.67528078e+17, 6.67518182e+17, 6.67576525e+17,\n",
       "        6.67558452e+17, 6.67632531e+17],\n",
       "       [6.23837540e+17, 6.23803387e+17, 6.23725734e+17, 6.23849429e+17,\n",
       "        6.23854651e+17, 6.23794728e+17, 6.23785451e+17, 6.23839945e+17,\n",
       "        6.23823178e+17, 6.23892310e+17],\n",
       "       [7.36645440e+17, 7.36605171e+17, 7.36513361e+17, 7.36659596e+17,\n",
       "        7.36665575e+17, 7.36594794e+17, 7.36583868e+17, 7.36648326e+17,\n",
       "        7.36628398e+17, 7.36710037e+17],\n",
       "       [5.60450695e+17, 5.60419977e+17, 5.60350227e+17, 5.60461346e+17,\n",
       "        5.60465950e+17, 5.60412143e+17, 5.60403759e+17, 5.60452825e+17,\n",
       "        5.60437672e+17, 5.60499829e+17],\n",
       "       [5.51776201e+17, 5.51745999e+17, 5.51677279e+17, 5.51786749e+17,\n",
       "        5.51791319e+17, 5.51738302e+17, 5.51730056e+17, 5.51778331e+17,\n",
       "        5.51763453e+17, 5.51824579e+17],\n",
       "       [4.05861009e+17, 4.05838778e+17, 4.05788304e+17, 4.05868774e+17,\n",
       "        4.05872142e+17, 4.05833143e+17, 4.05827062e+17, 4.05862555e+17,\n",
       "        4.05851595e+17, 4.05896606e+17],\n",
       "       [1.04234919e+18, 1.04229201e+18, 1.04216234e+18, 1.04236905e+18,\n",
       "        1.04237764e+18, 1.04227751e+18, 1.04226205e+18, 1.04235317e+18,\n",
       "        1.04232500e+18, 1.04244051e+18],\n",
       "       [3.30730727e+17, 3.30712619e+17, 3.30671456e+17, 3.30737083e+17,\n",
       "        3.30739798e+17, 3.30708015e+17, 3.30703067e+17, 3.30732067e+17,\n",
       "        3.30723065e+17, 3.30759761e+17],\n",
       "       [7.45503450e+17, 7.45462699e+17, 7.45369859e+17, 7.45517674e+17,\n",
       "        7.45523859e+17, 7.45452254e+17, 7.45441121e+17, 7.45506336e+17,\n",
       "        7.45486201e+17, 7.45568802e+17],\n",
       "       [6.18479070e+17, 6.18445191e+17, 6.18368157e+17, 6.18490821e+17,\n",
       "        6.18495975e+17, 6.18436533e+17, 6.18427324e+17, 6.18481475e+17,\n",
       "        6.18464708e+17, 6.18533290e+17],\n",
       "       [4.57601415e+17, 4.57576332e+17, 4.57519364e+17, 4.57610108e+17,\n",
       "        4.57613888e+17, 4.57569942e+17, 4.57563173e+17, 4.57603202e+17,\n",
       "        4.57590764e+17, 4.57641513e+17],\n",
       "       [5.86614261e+17, 5.86582169e+17, 5.86509052e+17, 5.86625462e+17,\n",
       "        5.86630342e+17, 5.86573923e+17, 5.86565264e+17, 5.86616529e+17,\n",
       "        5.86600655e+17, 5.86665732e+17],\n",
       "       [3.92887150e+17, 3.92865606e+17, 3.92816712e+17, 3.92894606e+17,\n",
       "        3.92897870e+17, 3.92860143e+17, 3.92854268e+17, 3.92888662e+17,\n",
       "        3.92878045e+17, 3.92921613e+17],\n",
       "       [5.29652068e+17, 5.29623069e+17, 5.29557167e+17, 5.29662239e+17,\n",
       "        5.29666568e+17, 5.29615647e+17, 5.29607813e+17, 5.29654130e+17,\n",
       "        5.29639768e+17, 5.29698557e+17],\n",
       "       [5.28452914e+17, 5.28423983e+17, 5.28358184e+17, 5.28462981e+17,\n",
       "        5.28467345e+17, 5.28416595e+17, 5.28408727e+17, 5.28454941e+17,\n",
       "        5.28440647e+17, 5.28499299e+17],\n",
       "       [1.90075771e+17, 1.90065360e+17, 1.90041686e+17, 1.90079378e+17,\n",
       "        1.90080959e+17, 1.90062679e+17, 1.90059879e+17, 1.90076492e+17,\n",
       "        1.90071338e+17, 1.90092401e+17],\n",
       "       [8.85861228e+16, 8.85812781e+16, 8.85702486e+16, 8.85878151e+16,\n",
       "        8.85885452e+16, 8.85800412e+16, 8.85787269e+16, 8.85864664e+16,\n",
       "        8.85840784e+16, 8.85939053e+16]], dtype=float32)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=566550, shape=(32,), dtype=bool, numpy=\n",
       "array([False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False])>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
